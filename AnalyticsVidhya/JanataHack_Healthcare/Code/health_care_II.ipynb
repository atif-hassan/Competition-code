{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## by Ankita Chatterjee\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data load\n",
    "\n",
    "train1 = pd.read_csv(\"train.csv\")\n",
    "train2 = pd.read_csv(\"submit_proba_train.csv\")\n",
    "\n",
    "\n",
    "test1 = pd.read_csv(\"test.csv\")\n",
    "test2 = pd.read_csv(\"submit_proba_test.csv\")\n",
    "\n",
    "train = pd.merge(train1, train2, on='case_id')\n",
    "test = pd.merge(test1, test2, on='case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 92017/92017 [00:19<00:00, 4613.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 318438/318438 [00:00<00:00, 1158718.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 39607/39607 [00:08<00:00, 4595.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 137057/137057 [00:00<00:00, 1184679.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#super feature\n",
    "\n",
    "hc_un = train[\"Hospital_code\"].unique()\n",
    "hc_un.sort()\n",
    "map_hc, map_pid = dict(), dict()\n",
    "for index, val in enumerate(hc_un):\n",
    "  map_hc[val] = index\n",
    "\n",
    "for pid, df in tqdm(train.groupby(\"patientid\")):\n",
    "  tmp = np.zeros(len(map_hc))\n",
    "  for val in df[\"Hospital_code\"].values:\n",
    "    tmp[map_hc[val]]+=1\n",
    "  map_pid[pid] = tmp\n",
    "\n",
    "# For train\n",
    "tmp = list()\n",
    "for val in tqdm(train[\"patientid\"].values):\n",
    "  tmp.append(map_pid[val])\n",
    "tmp = np.array(tmp)\n",
    "for i in range(len(map_hc)):\n",
    "  train[\"patientid_hospital_code_\"+str(i)] = tmp[:,i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hc_un = test[\"Hospital_code\"].unique()\n",
    "hc_un.sort()\n",
    "map_hc, map_pid = dict(), dict()\n",
    "for index, val in enumerate(hc_un):\n",
    "  map_hc[val] = index\n",
    "\n",
    "for pid, df in tqdm(test.groupby(\"patientid\")):\n",
    "  tmp = np.zeros(len(map_hc))\n",
    "  for val in df[\"Hospital_code\"].values:\n",
    "    tmp[map_hc[val]]+=1\n",
    "  map_pid[pid] = tmp\n",
    "\n",
    "# For test\n",
    "tmp = list()\n",
    "for val in tqdm(test[\"patientid\"].values):\n",
    "  tmp.append(map_pid[val])\n",
    "tmp = np.array(tmp)\n",
    "for i in range(len(map_hc)):\n",
    "  test[\"patientid_hospital_code_\"+str(i)] = tmp[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filling nan and specifying categorical variables\n",
    "\n",
    "#train[\"Bed Grade\"] = train.groupby([\"Hospital_code\"], sort=False)[\"Bed Grade\"].apply(lambda x: x.fillna(x.mean()))\n",
    "#test[\"Bed Grade\"] = test.groupby([\"Hospital_code\"], sort=False)[\"Bed Grade\"].apply(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# City_Code_Patient has nulls. Treat them as a separate code\n",
    "train[\"City_Code_Patient\"] = train[\"City_Code_Patient\"].fillna(39)\n",
    "test[\"City_Code_Patient\"] = test[\"City_Code_Patient\"].fillna(39)\n",
    "\n",
    "cols_cat = ['Hospital_code', 'City_Code_Hospital', \"Hospital_type_code\", \"Hospital_region_code\", \"Department\", \"Ward_Type\", \"Ward_Facility_Code\", 'City_Code_Patient']\n",
    "cols_cont = ['Available Extra Rooms in Hospital','Bed Grade', 'Visitors with Patient', 'Age', 'Admission_Deposit', \"Severity of Illness\", \"Type of Admission\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "train = train.drop(['patientid'], axis = 1)\n",
    "test = test.drop(['patientid'], axis = 1)\n",
    "train_case_ids = train['case_id']\n",
    "case_ids = test['case_id']\n",
    "train = train.drop(['case_id'], axis = 1)\n",
    "test = test.drop(['case_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Gender'] = [1 if i=='gynecology' else 0 for i in train.Department.values]\n",
    "test['Gender'] = [1 if i=='gynecology' else 0 for i in test.Department.values]\n",
    "\n",
    "df = train\n",
    "df_test = test1.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train[\"Department\"] = le.fit_transform(train[\"Department\"])\n",
    "test[\"Department\"] = le.transform(test[\"Department\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {'P':1, 'Q':2, 'R':3, 'S':4, 'T':5, 'U':6}\n",
    "\n",
    "train[\"Ward_Type\"] = train[\"Ward_Type\"].map(mp)\n",
    "test[\"Ward_Type\"] = test[\"Ward_Type\"].map(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7}\n",
    "\n",
    "train[\"Hospital_type_code\"] = train[\"Hospital_type_code\"].map(mp)\n",
    "test[\"Hospital_type_code\"] = test[\"Hospital_type_code\"].map(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Hospital_region_code\"] = le.fit_transform(train[\"Hospital_region_code\"])\n",
    "test[\"Hospital_region_code\"] = le.transform(test[\"Hospital_region_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {'A':6,'B':5,'C':4,'D':3,'E':2,'F':1}\n",
    "train[\"Ward_Facility_Code\"] = train[\"Ward_Facility_Code\"].map(mp)\n",
    "test[\"Ward_Facility_Code\"] = test[\"Ward_Facility_Code\"].map(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = {'Emergency':2, 'Urgent':3, 'Trauma':1}\n",
    "m3 = {'Minor':1, 'Moderate':2, 'Extreme':3}\n",
    "\n",
    "train['Type of Admission'] = train['Type of Admission'].map(m2)\n",
    "test['Type of Admission'] = test['Type of Admission'].map(m2)\n",
    "\n",
    "train['Severity of Illness'] = train['Severity of Illness'].map(m3)\n",
    "test['Severity of Illness'] = test['Severity of Illness'].map(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = {'0-10':0, '11-20':1, '21-30':2, '31-40':3,'41-50':4,'51-60':5,'61-70':6,'71-80':7,'81-90':8,'91-100':9,'More than 100 Days':10 }\n",
    "train['Age'] = train['Age'].map(m)\n",
    "train['Stay'] = train['Stay'].map(m)\n",
    "\n",
    "test['Age'] = test['Age'].map(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if hosp and patient are in same city\n",
    "city = train['City_Code_Hospital'].values\n",
    "patient = train['City_Code_Patient'].values\n",
    "val = []\n",
    "        \n",
    "for i in range(len(city)):\n",
    "  if city[i] == patient[i]:\n",
    "    val.append(1)\n",
    "  else:\n",
    "    val.append(0)\n",
    "train['hosp_patient_same'] = val\n",
    "\n",
    "city = test['City_Code_Hospital'].values\n",
    "patient = test['City_Code_Patient'].values\n",
    "val = []\n",
    "\n",
    "for i in range(len(city)):\n",
    "  if city[i] == patient[i]:\n",
    "    val.append(1)\n",
    "  else:\n",
    "    val.append(0)\n",
    "test['hosp_patient_same'] = val\n",
    "#hospitals per city\n",
    "import numpy as np\n",
    "df_comb = pd.concat([train,test], axis = 0)\n",
    "\n",
    "count = []\n",
    "for i in range(14):\n",
    "  count.append([])\n",
    "\n",
    "\n",
    "hosp = df_comb.Hospital_code.values\n",
    "city = df_comb.City_Code_Hospital.values\n",
    "\n",
    "for i in range(len(hosp)):\n",
    "  if hosp[i] not in count[city[i]]:\n",
    "    count[city[i]].append(hosp[i])\n",
    "\n",
    "res = []\n",
    "\n",
    "city = train.City_Code_Patient.values\n",
    "\n",
    "for i in range(len(city)):\n",
    "  try:\n",
    "    res.append( len(count[ int( city[i] ) ] ))\n",
    "  except:\n",
    "    res.append(0)\n",
    "\n",
    "train['max_hospitals'] = res\n",
    "\n",
    "res = []\n",
    "\n",
    "city = test.City_Code_Patient.values\n",
    "\n",
    "for i in range(len(city)):\n",
    "  try:\n",
    "    res.append( len(count[ int( city[i] ) ] ))\n",
    "  except:\n",
    "    res.append(0)\n",
    "test['max_hospitals'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['91-100' ], axis=1, inplace=True)\n",
    "test.drop(['91-100'  ], axis=1, inplace=True)\n",
    "#train['ward_score'] = train['Ward_Facility_Code'] * train['Ward_Type']\n",
    "#test['ward_score'] = test['Ward_Facility_Code'] * test['Ward_Type']\n",
    "#train['ward_bed_score'] = train['Ward_Facility_Code'] * train['Bed Grade']\n",
    "#test['ward_bed_score'] = test['Ward_Facility_Code'] * test['Bed Grade']\n",
    "train['add_age'] = train['Age'] * train['Type of Admission']\n",
    "test['add_age'] =test['Age'] * test['Type of Admission']\n",
    "comb = pd.concat([train,test], axis = 0)\n",
    "hosp = df_comb.Hospital_code.values\n",
    "dep = df_comb.Department.values\n",
    "\n",
    "#X_train, Y = train.drop([\"Stay\"], axis=1).values, train[\"Stay\"].values\n",
    "#X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, Y = train.drop(['max_hospitals',\"Stay\"], axis=1).values, train[\"Stay\"].values\n",
    "X_test = test.drop(['max_hospitals'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.43316683944334494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.42986837558508467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.4374077215468225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.43037099864920053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.4334495649169101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.4321751696406132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.4339029907011812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.4285624528776074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.430635838150289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n",
      "0.435819301331993\n",
      "Average:  0.43253592528430457\n"
     ]
    }
   ],
   "source": [
    "#oof predictions\n",
    "import numpy as np\n",
    "\n",
    "i=0\n",
    "setused=X_train\n",
    "targ=Y\n",
    "\n",
    "scores=[]\n",
    "splits=10\n",
    "\n",
    "cnf_matrix=[]\n",
    "sc = 0\n",
    "#oof_preds = [np.zeros((len(X_test)))]\n",
    "kfold, scores = KFold(n_splits=splits,shuffle= True, random_state=True), list()\n",
    "for train2, test2 in kfold.split(setused,targ):\n",
    "    x_train, x_test = setused[train2], setused[test2]\n",
    "    y_train, y_test = targ[train2], targ[test2]\n",
    "    eval_set = [(x_test,y_test)]\n",
    "    cat_feat = [df.columns.get_loc(i) for  i in ['Hospital_region_code','Hospital_code', 'City_Code_Hospital','Hospital_type_code','Department','City_Code_Patient', 'Gender']]\n",
    "    #model = LGBMClassifier(boosting_type='gbdt',learning_rate=0.1,n_estimstors=500,max_depth=15,random_state=22,categorical_feature=cat_feat) # n_estimaators=5000, max_depth=16,\n",
    "    \n",
    "    model = lgb.LGBMClassifier(boosting_type='gbdt', categorical_feature=cat_feat, objective= 'multiclass', num_leaves=80, min_data_in_leaf=307, max_depth=7, learning_rate=0.1)\n",
    "    #model = lgb.LGBMClassifier(random_state=22,categorical_feature=cat_feat)\n",
    "    #model = LogisticRegression(max_iter=1000, random_state=22)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict(x_test)\n",
    "    score = accuracy_score(y_test, preds)\n",
    "    scores.append(score)\n",
    "    print(score)    \n",
    "    sc += 1\n",
    "    if i == 0:\n",
    "      oof_preds = model.predict_proba(X_test)\n",
    "      i += 1\n",
    "    else:\n",
    "      oof_preds += model.predict_proba(X_test)\n",
    "oof_preds = oof_preds/sc\n",
    "\n",
    "print(\"Average: \", np.sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(oof_preds, axis = 1)\n",
    "\n",
    "new_preds2 = list()\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] == 0:\n",
    "        new_preds2.append('0-10')\n",
    "    elif preds[i] == 1:\n",
    "        new_preds2.append('11-20')\n",
    "    elif preds[i] == 2:\n",
    "        new_preds2.append('21-30')\n",
    "    elif preds[i] == 3:\n",
    "        new_preds2.append('31-40')\n",
    "    elif preds[i] == 4:\n",
    "        new_preds2.append('41-50')\n",
    "    elif preds[i] == 5:\n",
    "        new_preds2.append('51-60')\n",
    "    elif preds[i] == 6:\n",
    "        new_preds2.append('61-70')\n",
    "    elif preds[i] == 7:\n",
    "        new_preds2.append('71-80')\n",
    "    elif preds[i] == 8:\n",
    "        new_preds2.append('81-90')\n",
    "    elif preds[i] == 9:\n",
    "        new_preds2.append('91-100')\n",
    "    elif preds[i] == 10:\n",
    "        new_preds2.append('More than 100 Days')\n",
    "\n",
    "df_submit = pd.DataFrame({'case_id': df_test['case_id'].values, 'Stay':new_preds2})\n",
    "df_submit.to_csv('submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn = pd.read_csv('submit_proba.csv')\n",
    "id = df_nn.case_id.values\n",
    "df_nn.drop(['case_id'], axis=1, inplace=True)\n",
    "\n",
    "val = df_nn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankita\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1075: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=307, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=307\n"
     ]
    }
   ],
   "source": [
    "## total predictions\n",
    "cat_feat = [df.columns.get_loc(i) for  i in ['Hospital_region_code','Hospital_code', 'City_Code_Hospital','Hospital_type_code','Department','City_Code_Patient', 'Gender']]\n",
    "clf = lgb.LGBMClassifier(boosting_type='gbdt', categorical_feature=cat_feat, objective= 'multiclass', num_leaves=80, min_data_in_leaf=307, max_depth=7, learning_rate=0.1)\n",
    "#clf = lgb.LGBMClassifier(categorical_feature=cat_feat, randome_state=22)\n",
    "clf.fit(X_train, Y)\n",
    "probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model blending\n",
    "import numpy as np\n",
    "lgbm = 0.1\n",
    "nn = 0.9\n",
    "final_preds, new_pre = [], []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "  temp = []\n",
    "  for j in range(11):\n",
    "    x = 0.95*oof_preds[i][j] + 0.05*probs[i][j]\n",
    "    temp.append(x)\n",
    "  new_pre.append(temp)\n",
    "\n",
    "for i in range(len(preds)):\n",
    "  temp = []\n",
    "  for j in range(11):\n",
    "    x = lgbm*new_pre[i][j] + nn*val[i][j]\n",
    "    temp.append(x)\n",
    "  final_preds.append(temp)\n",
    "\n",
    "final_preds = np.argmax(final_preds, axis = 1)\n",
    "#final_preds = np.argmax(new_pre, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds2 = list()\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] == 0:\n",
    "        new_preds2.append('0-10')\n",
    "    elif preds[i] == 1:\n",
    "        new_preds2.append('11-20')\n",
    "    elif preds[i] == 2:\n",
    "        new_preds2.append('21-30')\n",
    "    elif preds[i] == 3:\n",
    "        new_preds2.append('31-40')\n",
    "    elif preds[i] == 4:\n",
    "        new_preds2.append('41-50')\n",
    "    elif preds[i] == 5:\n",
    "        new_preds2.append('51-60')\n",
    "    elif preds[i] == 6:\n",
    "        new_preds2.append('61-70')\n",
    "    elif preds[i] == 7:\n",
    "        new_preds2.append('71-80')\n",
    "    elif preds[i] == 8:\n",
    "        new_preds2.append('81-90')\n",
    "    elif preds[i] == 9:\n",
    "        new_preds2.append('91-100')\n",
    "    elif preds[i] == 10:\n",
    "        new_preds2.append('More than 100 Days')\n",
    "\n",
    "df_submit = pd.DataFrame({'case_id': df_test['case_id'].values, 'Stay':new_preds2})\n",
    "df_submit.to_csv('submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
